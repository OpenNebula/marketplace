---
name: Service Ray
version: 6.10.0-3-20250127
publisher: OpenNebula Systems
description: |-
  Appliance with preinstalled [Ray](https://www.ray.io/) framework for distributed computing and machine learning workloads.

  See the dedicated [documentation](https://github.com/OpenNebula/one-apps/wiki/ray_intro).
short_description: Appliance with preinstalled Ray framework
tags:
- ray
- service
format: qcow2
creation_time: 1737885730
os-id: Ubuntu
os-release: 22.04 LTS
os-arch: x86_64
hypervisor: KVM
opennebula_version: 6.0, 6.2, 6.4, 6.6, 6.8, 6.10
opennebula_template:
  context:
    network: 'YES'
    oneapp_ray_api_port: "$ONEAPP_RAY_API_PORT"
    oneapp_ray_api_route: "$ONEAPP_RAY_API_ROUTE"
    oneapp_ray_application_file64: "$ONEAPP_RAY_APPLICATION_FILE64"
    oneapp_ray_application_url: "$ONEAPP_RAY_APPLICATION_URL"
    oneapp_ray_model_id: "$ONEAPP_RAY_MODEL_ID"
    oneapp_ray_model_prompt: "$ONEAPP_RAY_MODEL_PROMPT"
    oneapp_ray_model_temperature: "$ONEAPP_RAY_MODEL_TEMPERATURE"
    oneapp_ray_model_token: "$ONEAPP_RAY_MODEL_TOKEN"
    ssh_public_key: "$USER[SSH_PUBLIC_KEY]"
  cpu: '1'
  graphics:
    listen: 0.0.0.0
    type: vnc
  inputs_order: >-
    ONEAPP_RAY_API_PORT,ONEAPP_RAY_CHATBOT_CPUS,ONEAPP_RAY_MODEL_ID,ONEAPP_RAY_MODEL_TEMPERATURE,ONEAPP_RAY_MODEL_TOKEN
  memory: '8192'
  os:
    arch: x86_64
  sched_requirements: 'HYPERVISOR=kvm & ARCH=x86_64'
  logo: images/logos/ray.png
  user_inputs:
    oneapp_ray_api_port: O|number|Port number for the API endpoint.| |8000
    oneapp_ray_api_route: O|text|Route path for the REST API exposed by the RAY application.| |/chat
    oneapp_ray_application_file64: O|text64|Python application to be deployed in the RAY framework (base64).| |
    oneapp_ray_application_url: O|text|URL to download the Python application for the RAY framework.| |
    oneapp_ray_model_id: M|list-multiple|Determines the AI model(s) to use for inference.|meta-llama/Llama-3.2-3B-Instruct,Qwen/Qwen2.5-3B-Instruct,utter-project/EuroLLM-1.7B-Instruct|
    oneapp_ray_model_prompt: O|text|Starting directive for model responses. | |You are a helpful assisstant. Answer the question.
    oneapp_ray_model_temperature: M|number-float|Temperature parameter for model outputs, controlling the randomness of generated text.| |0.1
    oneapp_ray_model_token: M|password|Provides the authentication token required to access the specified AI model. | |
logo: ray.png
images:
- name: service_Ray
  url: >-
    https://d24fmfybwxpuhu.cloudfront.net/service_Ray-6.10.0-3-20250127.qcow2
  type: OS
  dev_prefix: vd
  driver: qcow2
  size: 8589934592
  checksum:
    md5: 91c5dcb285893d266eadd38dd136b51c
    sha256: c5204d2d51a8fa1c218aecc83874382f33697004728e076a87e3d07197236b51
